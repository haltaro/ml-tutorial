{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 教師なし学習入門\n",
    "\n",
    "## 5.1 はじめに\n",
    "[1.scikit-learn入門](https://github.com/haltaro/ml-tutorial/blob/master/01.intro_to_scikit-learn.ipynb)でご紹介したように，機械学習は，教師あり学習（Supervised learning）と教師なし学習（Unsupervised learning）に大別されます．\n",
    "本ノートブックでは，教師なし学習について簡単にご紹介します．\n",
    "\n",
    "教師なし学習（Unsupervised learning）とは，訓練データが，予測対象（Target）の情報を持たない学習問題を指します．\n",
    "今回は特に，[次元削減](http://scikit-learn.org/stable/modules/unsupervised_reduction.html)および[クラスタリング](http://scikit-learn.org/stable/modules/clustering.html)について，代表的な手法をご紹介します．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 次元削減\n",
    "\n",
    "[次元削減（Dimentionality reduction）](http://scikit-learn.org/stable/modules/decomposition.html#decompositions)とは，出来る限り情報量を保ちつつ，データを低次元に写像することです．\n",
    "次元削減の目的は，可視化のための前処理や，データの不可逆圧縮です．\n",
    "本ノートブックでは，代表的な手法である[主成分分析](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA)（PCA; Principal component analysis）を取り扱います．その他の手法については，[scikit-learn, 4.4. Unsupervised dimensionality reduction](http://scikit-learn.org/stable/modules/unsupervised_reduction.html)および[scikit-learn, 2.5. Decomposing signals in components (matrix factorization problems)](http://scikit-learn.org/stable/modules/decomposition.html#decompositions)をご参照ください．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 主成分分析とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 デモ：主成分分析による可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 デモ：主成分分析による非可逆圧縮"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[クラスタリング](http://scikit-learn.org/stable/modules/clustering.html)とは，分類対象の集合を，内的結合と外的分離が達成されるような部分集合に分割することです（大橋 靖雄: 分類手法概論, 計測と制御, Vol.24, No.11, pp.999-1006 (1985)）．\n",
    "\n",
    "本ノートブックでは，代表的な手法である[K-means法](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)のみ取り扱います．クラスタリング全般については，[神嶌先生の解説記事]()がとてもわかりやすいのでおすすめです．他のクラスタリング手法については，[scikit-learn, 2.3. Clustering](http://scikit-learn.org/stable/modules/clustering.html)でも言及されています．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 K-means法とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 デモ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
